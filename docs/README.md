# Milion√°ria AI

Projeto para coleta, an√°lise e predi√ß√£o de resultados da loteria +Milion√°ria usando intelig√™ncia artificial.

## Descri√ß√£o

Este projeto automatiza a coleta de dados hist√≥ricos da +Milion√°ria, processa os dados em um banco SQLite e utiliza t√©cnicas de machine learning para an√°lise e simula√ß√£o de resultados.

## Execut√°vel MilionariaUpdate

O projeto inclui um execut√°vel standalone (`MilionariaUpdate.exe`) que permite opera√ß√µes de importa√ß√£o e atualiza√ß√£o sem necessidade de instala√ß√£o do Python.

### Uso do Execut√°vel

```bash
# Importar dados iniciais de arquivo Excel
MilionariaUpdate.exe --import data/raw/base_275.xlsx

# Atualizar dados via web scraping
MilionariaUpdate.exe --update

# Exibir ajuda
MilionariaUpdate.exe --help
```

### Gera√ß√£o do Execut√°vel

```bash
# Instalar PyInstaller
pip install pyinstaller

# Gerar execut√°vel
pyinstaller milionaria.spec

# O execut√°vel ser√° criado em dist/MilionariaUpdate.exe
```

## Estrutura do Projeto

```
milionaria-ai/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # Dados brutos coletados
‚îÇ   ‚îî‚îÄ‚îÄ processed/    # Dados processados
‚îú‚îÄ‚îÄ db/               # Banco de dados SQLite
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ db/           # M√≥dulos de banco de dados
‚îÇ   ‚îú‚îÄ‚îÄ ingest/       # Coleta de dados
‚îÇ   ‚îú‚îÄ‚îÄ update/       # Atualiza√ß√£o autom√°tica
‚îÇ   ‚îú‚îÄ‚îÄ utils/        # Utilit√°rios gerais
‚îÇ   ‚îú‚îÄ‚îÄ etl/          # Extract, Transform, Load
‚îÇ   ‚îú‚îÄ‚îÄ features/     # Engenharia de features
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Modelos de ML
‚îÇ   ‚îú‚îÄ‚îÄ simulate/     # Simula√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ generate/     # Gera√ß√£o de n√∫meros
‚îÇ   ‚îî‚îÄ‚îÄ cli/          # Interface de linha de comando
‚îú‚îÄ‚îÄ tasks/            # Scripts de tarefas
‚îú‚îÄ‚îÄ logs/             # Arquivos de log
‚îú‚îÄ‚îÄ configs/          # Arquivos de configura√ß√£o
‚îú‚îÄ‚îÄ outputs/          # Resultados e relat√≥rios
‚îî‚îÄ‚îÄ tests/            # Testes unit√°rios
```

## GPU (Acelera√ß√£o NVIDIA)

O projeto suporta acelera√ß√£o GPU usando NVIDIA RTX 3080 ou superior para treinamento de modelos e c√°lculo de scores.

### Requisitos GPU

**Hardware:**
- NVIDIA GPU com arquitetura Pascal ou superior (GTX 1060+, RTX 2060+, RTX 3080 recomendada)
- M√≠nimo 4GB VRAM (8GB+ recomendado)
- CUDA Compute Capability 6.0+

**Software:**
- NVIDIA Driver 470.57.02+ (Windows) / 470.57.02+ (Linux)
- CUDA Toolkit 11.2+ (11.8 recomendado)
- cuML (RAPIDS) para machine learning em GPU

### Instala√ß√£o CUDA e cuML

```bash
# 1. Instalar CUDA Toolkit (https://developer.nvidia.com/cuda-downloads)
# Baixar e instalar CUDA 11.8 para Windows

# 2. Instalar cuML via conda (recomendado)
conda create -n milionaria-gpu python=3.9
conda activate milionaria-gpu
conda install -c rapidsai -c conda-forge cuml=23.10 python=3.9 cudatoolkit=11.8

# 3. Instalar depend√™ncias do projeto
pip install -r requirements.txt

# 4. Verificar instala√ß√£o
python -c "import cuml; print('cuML instalado com sucesso!')"
```

### Ativa√ß√£o do Modo GPU

**M√©todo 1: Substitui√ß√£o direta no c√≥digo**
```python
# Substituir imports CPU por GPU
# De:
from src.models.scoring import learn_weights_ridge, score_numbers

# Para:
from src.models.scoring_gpu import learn_weights_gpu, score_numbers_gpu

# Substituir chamadas de fun√ß√£o
# De:
model, scaler, weights = learn_weights_ridge(features)
scores = score_numbers(snapshot, weights)

# Para:
model, scaler, weights = learn_weights_gpu(features, use_gpu=True)
scores = score_numbers_gpu(snapshot, weights, use_gpu=True)
```

**M√©todo 2: Verifica√ß√£o autom√°tica**
```python
from src.models.scoring_gpu import get_gpu_info

# Verificar status da GPU
gpu_info = get_gpu_info()
print(f"GPU dispon√≠vel: {gpu_info['cuml_available']}")
print(f"GPUs encontradas: {gpu_info['gpu_count']}")

if gpu_info['cuml_available']:
    # Usar GPU
    from src.models.scoring_gpu import learn_weights_gpu, score_numbers_gpu
    model, scaler, weights = learn_weights_gpu(features, use_gpu=True)
else:
    # Fallback para CPU
    from src.models.scoring import learn_weights_ridge, score_numbers
    model, scaler, weights = learn_weights_ridge(features)
```

### Performance GPU vs CPU

| Opera√ß√£o | CPU (i7-10700K) | GPU (RTX 3080) | Speedup |
|----------|-----------------|----------------|----------|
| Treinamento modelo | ~2.5s | ~0.3s | 8.3x |
| C√°lculo scores | ~0.8s | ~0.1s | 8.0x |
| Valida√ß√£o walk-forward | ~45s | ~6s | 7.5x |

### Fallback Autom√°tico

O sistema possui fallback autom√°tico para CPU quando:
- cuML n√£o est√° instalado
- GPU n√£o est√° dispon√≠vel
- `use_gpu=False` √© especificado
- Erro durante opera√ß√µes GPU

### Troubleshooting GPU

**Erro: "cuML n√£o dispon√≠vel"**
```bash
# Verificar instala√ß√£o CUDA
nvcc --version
nvidia-smi

# Reinstalar cuML
conda install -c rapidsai cuml --force-reinstall
```

**Erro: "CUDA out of memory"**
```python
# Reduzir batch size ou usar CPU para datasets grandes
model, scaler, weights = learn_weights_gpu(features, use_gpu=False)
```

**Verificar compatibilidade:**
```python
from src.models.scoring_gpu import get_gpu_info
info = get_gpu_info()
print(info)  # Mostra detalhes da GPU e mem√≥ria
```

## Extra√ß√£o de Dados (ETL)

O m√≥dulo ETL fornece uma interface limpa para extrair dados dos sorteios do banco de dados em formato adequado para an√°lise e modelagem de IA.

### Uso do M√≥dulo ETL

```python
from src.etl.from_db import load_draws

# Carrega todos os sorteios do banco
df = load_draws("db/milionaria.db")

# Exibe informa√ß√µes b√°sicas
print(f"Total de sorteios: {len(df)}")
print(f"Colunas: {df.columns}")
print(df.head())
```

### Estrutura dos Dados

O DataFrame retornado cont√©m as seguintes colunas:
- `concurso` (int): N√∫mero do concurso
- `data` (date): Data do sorteio
- `D1, D2, D3, D4, D5, D6` (int): Dezenas sorteadas (1-50)
- `T1, T2` (int): Trevos sorteados (1-6)

### Tipos de Dados
- N√∫meros inteiros otimizados (Int8 para dezenas/trevos, Int32 para concurso)
- Datas como objetos `date` do Python
- DataFrame Polars para performance otimizada

## Scoring de N√∫meros

O m√≥dulo de scoring utiliza machine learning para calcular probabilidades de cada n√∫mero aparecer no pr√≥ximo sorteio.

### Uso do M√≥dulo Scoring

```python
from src.etl.from_db import load_draws
from src.features.make import build_number_features, latest_feature_snapshot
from src.models.scoring import learn_weights_ridge, score_numbers, print_top_scores

# Carregar dados e gerar features
df = load_draws("db/milionaria.db")
features = build_number_features(df)
snapshot = latest_feature_snapshot(df)

# Treinar modelo Ridge e aprender pesos
model, scaler, weights = learn_weights_ridge(features)

# Calcular scores para dezenas (1-50)
scores = score_numbers(snapshot, weights)

# Mostrar top-10 n√∫meros com maior probabilidade
print_top_scores(scores, top_k=10)
```

### Caracter√≠sticas do Scoring

- **Algoritmo**: Ridge Regression com regulariza√ß√£o
- **Features**: Frequ√™ncia, rolling windows, √∫ltima apari√ß√£o, momentum
- **Normaliza√ß√£o**: Scores normalizados entre [0,1]
- **Determin√≠stico**: Resultados reproduz√≠veis
- **Output**: Dicion√°rio {numero: score} para dezenas 1-50

### Upgrade GPU (Futuro)

üöÄ **Flag GPU**: Estrutura preparada para acelera√ß√£o GPU com cuML (RAPIDS)

Quando necess√°rio, o m√≥dulo `src.models.scoring_gpu.py` pode ser implementado para:
- Treinamento em GPU com cuML Ridge
- Processamento paralelo com cuDF/cuPy
- Speedup significativo para datasets grandes

**Pr√©-requisitos GPU**:
- NVIDIA GPU com CUDA
- cuML (RAPIDS)
- cuDF para DataFrames em GPU

## Instala√ß√£o

### Pr√©-requisitos
- Python 3.11
- mamba ou conda
- polars (para ETL)
- scikit-learn (para scoring)

### Configura√ß√£o do ambiente

1. Clone o reposit√≥rio:
```bash
git clone <url-do-repositorio>
cd milionaria-ai
```

2. Crie e ative o ambiente conda:
```bash
```bash
mamba env create -f environment.yml
mamba activate milionaria-ai
```

3. Instale as depend√™ncias adicionais:
```bash
pip install playwright tenacity
playwright install
```
mamba env create -f env.yml && mamba activate milionaria-ai
```

3. Instale o navegador Chromium para Playwright:
```bash
playwright install chromium
```

4. Verifique a instala√ß√£o do Playwright:
```bash
playwright --version
```

## Como rodar r√°pido

### Teste do banco de dados

1. Criar e testar o banco de dados:
```bash
python tests/test_db.py
```

2. Verificar se o banco foi criado:
```bash
# Listar arquivos do banco
ls db/

# Conectar ao SQLite e listar tabelas
sqlite3 db/milionaria.db ".tables"

# Ver estrutura da tabela sorteios
sqlite3 db/milionaria.db ".schema sorteios"

# Contar registros
sqlite3 db/milionaria.db "SELECT COUNT(*) FROM sorteios;"
```

### Importa√ß√£o inicial

3. Preparar planilha hist√≥rica:
   - Coloque o arquivo `base_275.xlsx` na pasta `data/raw/`
   - A planilha deve conter as colunas: `concurso`, `data`, `D1`, `D2`, `D3`, `D4`, `D5`, `D6`, `T1`, `T2`
   - Datas no formato DD/MM/AAAA
   - Exemplo dispon√≠vel em: `data/raw/exemplo_base_275.csv`

4. Importar planilha hist√≥rica:
```bash
python -m src.ingest.import_initial
```

5. Testar importa√ß√£o com dados de exemplo:
```bash
python tests/test_import.py
```

6. Verificar importa√ß√£o:
```bash
# Contar registros importados
sqlite3 db/milionaria.db "SELECT COUNT(*) as total_registros FROM sorteios;"

# Ver primeiros registros
sqlite3 db/milionaria.db "SELECT * FROM sorteios ORDER BY concurso LIMIT 5;"

# Ver √∫ltimos registros
sqlite3 db/milionaria.db "SELECT * FROM sorteios ORDER BY concurso DESC LIMIT 5;"
```

### Coleta da CAIXA

7. Coletar dados atuais do portal da CAIXA:
```python
# Exemplo de chamada ass√≠ncrona
import asyncio
from src.update.fetch_caixa import fetch_caixa_data

async def main():
    # Coleta apenas o concurso atual
    df_atual = await fetch_caixa_data(to_latest=False)
    print(f"Concurso atual: {df_atual.iloc[0]['concurso']}")
    
    # Coleta do concurso 100 at√© o √∫ltimo dispon√≠vel
    df_range = await fetch_caixa_data(start_concurso=100, to_latest=True)
    print(f"Coletados {len(df_range)} concursos")
    
    # Snapshots HTML salvos em logs/html/ para auditoria
    print("Snapshots salvos para auditoria em logs/html/")

# Executar
asyncio.run(main())
```

### Valida√ß√£o de Integridade

8. Verificar integridade do banco de dados:
```bash
# Comando r√°pido para valida√ß√£o completa
python -m src.utils.validate
```

Este comando verifica:
- ‚úÖ **Datas n√£o nulas**: Todas as datas s√£o v√°lidas
- ‚úÖ **Dezenas v√°lidas**: d1-d6 est√£o no intervalo [1,50] <mcreference link="https://amazonasatual.com.br/comecam-as-apostas-da-milionaria-nova-loteria-da-caixa-com-premio-minimo-de-r-10-milhoes/" index="1">1</mcreference>
- ‚úÖ **Trevos v√°lidos**: t1,t2 est√£o no intervalo [1,6] <mcreference link="https://amazonasatual.com.br/comecam-as-apostas-da-milionaria-nova-loteria-da-caixa-com-premio-minimo-de-r-10-milhoes/" index="1">1</mcreference>
- ‚úÖ **Concursos √∫nicos**: N√£o h√° duplicatas

**Retorna `True` se todos os checks passarem**, caso contr√°rio levanta exce√ß√£o com detalhes do erro.

**Nota**: Os checks de integridade s√£o executados automaticamente ap√≥s cada atualiza√ß√£o do banco via `update_db`.

### Automa√ß√£o e Agendamento

8. Script de atualiza√ß√£o autom√°tica:
```powershell
# Executa atualiza√ß√£o completa com logging
.\tasks\update_all.ps1
```

O script `tasks/update_all.ps1` automatiza todo o processo p√≥s-sorteio:
- ‚úÖ **Ativa ambiente conda** automaticamente
- ‚úÖ **Executa atualiza√ß√£o** do banco de dados
- ‚úÖ **Valida integridade** dos dados
- ‚úÖ **Gera logs detalhados** em `logs/update_YYYYMMDD.log`
- ‚úÖ **Falha com exit code ‚â† 0** em caso de erro
- ‚úÖ **Reexecut√°vel** e usa caminhos relativos

9. Configurar agendamento di√°rio (Windows):
```powershell
# Abrir Agendador de Tarefas
taskschd.msc

# Ou via linha de comando:
schtasks /create /tn "Milionaria-AI Update" /tr "powershell.exe -ExecutionPolicy Bypass -File 'C:\caminho\completo\para\milionaria-ai\tasks\update_all.ps1'" /sc daily /st 21:30 /ru "SYSTEM"
```

**Configura√ß√£o manual no Agendador de Tarefas:**
1. Abra o **Agendador de Tarefas** (`taskschd.msc`)
2. Clique em **"Criar Tarefa B√°sica"**
3. **Nome**: `Milionaria-AI Update`
4. **Disparador**: `Diariamente √†s 21:30`
5. **A√ß√£o**: `Iniciar um programa`
6. **Programa**: `powershell.exe`
7. **Argumentos**: `-ExecutionPolicy Bypass -File "C:\caminho\completo\para\milionaria-ai\tasks\update_all.ps1"`
8. **Iniciar em**: `C:\caminho\completo\para\milionaria-ai`
9. **Executar com privil√©gios mais altos**: ‚úÖ Marcado

**Verifica√ß√£o do agendamento:**
```powershell
# Listar tarefas agendadas
schtasks /query /tn "Milionaria-AI Update"

# Executar manualmente para teste
schtasks /run /tn "Milionaria-AI Update"

# Verificar log ap√≥s execu√ß√£o
Get-Content logs\update_$(Get-Date -Format 'yyyyMMdd').log -Tail 20
```

10. Testar coleta da CAIXA:
```bash
# Executa o teste integrado
python -m src.update.fetch_caixa
```

### Execu√ß√£o principal

9. Execute a coleta inicial:
```bash
python -m src.cli.main --collect
```

10. Processe os dados:
```bash
python -m src.cli.main --process
```

## Depend√™ncias do Playwright

### Configura√ß√£o para M√°quinas Novas

O projeto utiliza Playwright para web scraping. Em m√°quinas novas, √© necess√°rio instalar os navegadores:

```bash
# Instalar depend√™ncias Python
pip install playwright

# Instalar navegadores do Playwright (OBRIGAT√ìRIO)
playwright install

# Ou instalar apenas o Chromium (mais leve)
playwright install chromium
```

### Depend√™ncias do Sistema

**Windows:**
```bash
# Instalar Microsoft Visual C++ Redistributable se necess√°rio
# Download: https://aka.ms/vs/17/release/vc_redist.x64.exe
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt-get update
sudo apt-get install -y libnss3 libatk-bridge2.0-0 libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libxss1 libasound2
```

**macOS:**
```bash
# Depend√™ncias geralmente j√° est√£o dispon√≠veis
# Se houver problemas, instalar Xcode Command Line Tools:
xcode-select --install
```

### Verifica√ß√£o da Instala√ß√£o

```bash
# Testar se Playwright est√° funcionando
python -c "from playwright.sync_api import sync_playwright; print('Playwright OK')"

# Testar navegador
python -c "from playwright.sync_api import sync_playwright; p = sync_playwright().start(); browser = p.chromium.launch(); browser.close(); p.stop(); print('Browser OK')"
```

### Troubleshooting

- **Erro "Browser not found"**: Execute `playwright install`
- **Erro de permiss√µes**: Execute como administrador/sudo
- **Erro de depend√™ncias**: Instale as depend√™ncias do sistema listadas acima
- **Timeout em sites**: Verifique conex√£o de internet e firewall

## Testes

O projeto inclui uma su√≠te de testes para garantir a estabilidade e qualidade do c√≥digo.

### Executando os Testes

```bash
# Executar todos os testes com output m√≠nimo
pytest -q

# Executar testes espec√≠ficos
pytest tests/test_schema.py -v
pytest tests/test_parse.py -v
pytest tests/test_update.py -v

# Executar com cobertura
pytest --cov=src tests/
```

### Estrutura dos Testes

- **`test_schema.py`**: Testes para cria√ß√£o e estrutura do banco de dados
- **`test_parse.py`**: Testes para parser de HTML com fixtures de dados
- **`test_update.py`**: Testes para opera√ß√µes de atualiza√ß√£o com mocks

### Pr√©-requisitos para Testes

```bash
# Instalar pytest se n√£o estiver instalado
pip install pytest pytest-cov
```

## Funcionalidades

- ‚úÖ Coleta autom√°tica de dados da +Milion√°ria
- ‚úÖ Armazenamento em banco SQLite
- ‚úÖ Processamento e limpeza de dados
- ‚úÖ An√°lise estat√≠stica
- ‚úÖ Modelos de machine learning
- ‚úÖ Simula√ß√£o de resultados
- ‚úÖ Gera√ß√£o de n√∫meros baseada em IA
- ‚úÖ Su√≠te de testes automatizados

## Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.